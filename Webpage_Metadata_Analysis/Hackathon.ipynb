{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tldextract python-whois requests beautifulsoup4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cga_ChVDqhIf",
        "outputId": "b2f6be4c-5c4f-430e-a2b0-12b2cca9da54"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.12/dist-packages (5.3.0)\n",
            "Requirement already satisfied: python-whois in /usr/local/lib/python3.12/dist-packages (0.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from tldextract) (3.10)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.12/dist-packages (from tldextract) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract) (3.19.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from python-whois) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->python-whois) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pUKwNWyg2d5",
        "outputId": "937b40aa-be00-4e8d-8cd1-cc6b08e79407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4012963490.py:38: DeprecationWarning: The 'registered_domain' property is deprecated and will be removed in the next major version. Use 'top_domain_under_public_suffix' instead, which has the same behavior but a more accurate name.\n",
            "  domain = extracted.registered_domain\n",
            "/tmp/ipython-input-4012963490.py:57: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  now = datetime.utcnow()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "URL: https://google.com\n",
            "Decision Tree → LEGITIMATE (No strong or weak suspicious patterns detected) | Domain age: 340 months | Months to expire: 36\n",
            "\n",
            "============================================================\n",
            "\n",
            "URL: http://facebook.com\n",
            "Decision Tree → LEGITIMATE (No strong or weak suspicious patterns detected) | Domain age: 346 months | Months to expire: 104\n",
            "\n",
            "============================================================\n",
            "\n",
            "URL: http://writeassociate.com/test/Portal/inicio/IO8Hc30w_Eq8DfVjyJGvwEO4GhAnH48CqLwGx-uH4XXCpAPCJlRkBsaGmGQ6QgAIyLKwQ/www.Bancasaleon.com.do/bhdi/\n",
            "Decision Tree → SUSPICIOUS (URL unreachable or dead) | Domain age: 5 months | Months to expire: 6\n",
            "\n",
            "============================================================\n",
            "\n",
            "URL: http://acornpresscanada.com/x487kjfdsd9274r98yuofiwo5uodjld2/chase-home/verification-card.php?https://chaseonline.chase.com/Logon.aspx?LOB=RBGLogon\n",
            "Decision Tree → SUSPICIOUS (URL unreachable or dead) | Domain age: 293 months | Months to expire: 34\n",
            "\n",
            "============================================================\n",
            "\n",
            "URL: https://tubuh-syarikat.com/plugins/fields/files/\n",
            "Decision Tree → PHISHING (Domain expiring in 0 months) | Domain age: 11 months | Months to expire: 0\n",
            "\n",
            "============================================================\n",
            "\n",
            "URL: http://webmasteradmin.ukit.me/\n",
            "Decision Tree → PHISHING (Domain expiring in 3 months) | Domain age: 106 months | Months to expire: 3\n",
            "\n",
            "============================================================\n",
            "\n",
            "URL: https://youtube.com\n",
            "Decision Tree → LEGITIMATE (No strong or weak suspicious patterns detected) | Domain age: 250 months | Months to expire: 5\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import requests\n",
        "import tldextract\n",
        "import whois\n",
        "from datetime import datetime\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Known free hosting domains\n",
        "FREE_HOSTING_DOMAINS = [\n",
        "    \"weebly.com\", \"wixsite.com\", \"ukit.me\",\n",
        "    \"000webhostapp.com\", \"wordpress.com\",\n",
        "    \"blogspot.com\", \"yolasite.com\", \"tripod.com\"\n",
        "]\n",
        "\n",
        "# Suspicious keywords in URL path\n",
        "SUSPICIOUS_KEYWORDS = [\n",
        "    \"login\", \"signin\", \"secure\", \"verify\", \"account\",\n",
        "    \"update\", \"password\", \"outlook\", \"office\", \"paypal\",\n",
        "    \"banking\", \"webmail\", \"inbox\", \"light.aspx\"\n",
        "]\n",
        "\n",
        "SUSPICIOUS_EXTENSIONS = [\".php\", \".asp\", \".aspx\", \".cgi\", \".exe\"]\n",
        "SUSPICIOUS_QUERY_TOKENS = [\"id=\", \"rand=\", \"login\", \"session\"]\n",
        "\n",
        "# Checking if URL is reachable\n",
        "def is_url_alive(url):\n",
        "    try:\n",
        "        resp = requests.head(url, timeout=5)\n",
        "        return resp.status_code < 400\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Extracting features from URL\n",
        "def extract_features(url):\n",
        "    features = {}\n",
        "    parsed = urlparse(url)\n",
        "    extracted = tldextract.extract(url)\n",
        "    domain = extracted.registered_domain\n",
        "    subdomain = extracted.subdomain\n",
        "    path = parsed.path.lower()\n",
        "    query = parsed.query.lower()\n",
        "\n",
        "    # Hard rules\n",
        "    ip_pattern = re.compile(r\"(\\d{1,3}\\.){3}\\d{1,3}\")\n",
        "    features['has_ip_in_url'] = bool(ip_pattern.search(url))\n",
        "    features['url_length'] = len(url)\n",
        "    features['has_at_symbol'] = \"@\" in url\n",
        "    features['has_dash_in_domain'] = \"-\" in extracted.domain\n",
        "    features['subdomain_count'] = 0 if not subdomain else subdomain.count(\".\") + 1\n",
        "    features['https_token_in_domain'] = \"https\" in extracted.domain.lower()\n",
        "\n",
        "    # WHOIS info\n",
        "    try:\n",
        "        domain_info = whois.whois(domain)\n",
        "        creation_date = domain_info.creation_date\n",
        "        expiration_date = domain_info.expiration_date\n",
        "        now = datetime.utcnow()\n",
        "\n",
        "        if isinstance(creation_date, list):\n",
        "            creation_date = creation_date[0]\n",
        "        if isinstance(expiration_date, list):\n",
        "            expiration_date = expiration_date[0]\n",
        "\n",
        "        features['domain_age_months'] = (now - creation_date).days // 30 if creation_date else 0\n",
        "        features['registration_length_months'] = (expiration_date - creation_date).days // 30 if creation_date and expiration_date else 0\n",
        "        features['dns_record_found'] = True\n",
        "        features['months_to_expire'] = max((expiration_date - now).days // 30, 0) if expiration_date else 0\n",
        "    except:\n",
        "        features['domain_age_months'] = 0\n",
        "        features['registration_length_months'] = 0\n",
        "        features['dns_record_found'] = False\n",
        "        features['months_to_expire'] = 0\n",
        "\n",
        "    if features['has_ip_in_url']:\n",
        "        features['dns_record_found'] = False\n",
        "\n",
        "    # Path features\n",
        "    features['path_depth'] = path.count(\"/\") if path else 0\n",
        "    features['suspicious_path_keyword'] = any(k in path for k in SUSPICIOUS_KEYWORDS)\n",
        "    features['suspicious_extension'] = any(path.endswith(ext) for ext in SUSPICIOUS_EXTENSIONS)\n",
        "    features['suspicious_query_token'] = any(tok in query for tok in SUSPICIOUS_QUERY_TOKENS)\n",
        "\n",
        "    # Free hosting\n",
        "    features['is_free_hosting'] = domain in FREE_HOSTING_DOMAINS\n",
        "\n",
        "    # URL reachability\n",
        "    features['url_alive'] = is_url_alive(url)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Decision tree classification\n",
        "def decision_tree_classify(features, url):\n",
        "    # Hard phishing rules\n",
        "    if features['has_ip_in_url']:\n",
        "        return \"phishing\", \"Contains IP in URL\"\n",
        "    if features['has_at_symbol']:\n",
        "        return \"phishing\", \"Contains '@' in URL\"\n",
        "    if not features['dns_record_found']:\n",
        "        return \"phishing\", \"No DNS record found\"\n",
        "    if features['https_token_in_domain']:\n",
        "        return \"phishing\", \"Domain contains 'https' token\"\n",
        "    if features['domain_age_months'] == 0:\n",
        "        return \"phishing\", \"Domain age missing or 0 months\"\n",
        "    if features['months_to_expire'] <= 3:\n",
        "        return \"phishing\", f\"Domain expiring in {features['months_to_expire']} months\"\n",
        "\n",
        "    # URL reachability check\n",
        "    if not features['url_alive']:\n",
        "        return \"suspicious\", \"URL unreachable or dead\"\n",
        "\n",
        "    # Strong suspicious signals\n",
        "    suspicious_reasons = []\n",
        "    if features['is_free_hosting']:\n",
        "        suspicious_reasons.append(\"Free hosting domain\")\n",
        "    if features['suspicious_path_keyword']:\n",
        "        suspicious_reasons.append(\"Suspicious keyword in path\")\n",
        "    if features['has_dash_in_domain']:\n",
        "        suspicious_reasons.append(\"Dash in domain\")\n",
        "\n",
        "    # Weak signals\n",
        "    weak_signals = 0\n",
        "    if features['suspicious_extension']:\n",
        "        weak_signals += 1\n",
        "    if features['suspicious_query_token']:\n",
        "        weak_signals += 1\n",
        "    if features['path_depth'] >= 3:\n",
        "        weak_signals += 1\n",
        "    if weak_signals >= 2:\n",
        "        suspicious_reasons.append(\"Multiple weak suspicious signals (extension/query/path depth)\")\n",
        "\n",
        "    if suspicious_reasons:\n",
        "        return \"suspicious\", \", \".join(suspicious_reasons)\n",
        "\n",
        "    return \"legitimate\", \"No strong or weak suspicious patterns detected\"\n",
        "\n",
        "# Runner\n",
        "def classify_url(url):\n",
        "    features = extract_features(url)\n",
        "    label, reason = decision_tree_classify(features, url)\n",
        "\n",
        "    activity_info = (f\" | Domain age: {features['domain_age_months']} months\"\n",
        "                     f\" | Months to expire: {features['months_to_expire']}\")\n",
        "\n",
        "    if label == \"legitimate\":\n",
        "        print(f\"\\nURL: {url}\\nDecision Tree → LEGITIMATE ({reason}){activity_info}\")\n",
        "    elif label == \"phishing\":\n",
        "        print(f\"\\nURL: {url}\\nDecision Tree → PHISHING ({reason}){activity_info}\")\n",
        "    else:\n",
        "        print(f\"\\nURL: {url}\\nDecision Tree → SUSPICIOUS ({reason}){activity_info}\")\n",
        "\n",
        "# Test URLs\n",
        "test_urls = [\n",
        "    \"https://google.com\",\n",
        "    \"http://facebook.com\",\n",
        "    \"http://writeassociate.com/test/Portal/inicio/IO8Hc30w_Eq8DfVjyJGvwEO4GhAnH48CqLwGx-uH4XXCpAPCJlRkBsaGmGQ6QgAIyLKwQ/www.Bancasaleon.com.do/bhdi/\", # Phishing site\n",
        "    \"http://acornpresscanada.com/x487kjfdsd9274r98yuofiwo5uodjld2/chase-home/verification-card.php?https://chaseonline.chase.com/Logon.aspx?LOB=RBGLogon\", #Phising site\n",
        "    \"https://tubuh-syarikat.com/plugins/fields/files/\",# Phising Site\n",
        "    \"http://webmasteradmin.ukit.me/\",\n",
        "    \"https://youtube.com\"\n",
        "]\n",
        "\n",
        "for u in test_urls:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    classify_url(u)\n"
      ]
    }
  ]
}